# -*- coding: utf-8 -*-
"""VGGNet_Keras

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1b2r5hppjM5f4n3G9qJGN9Q7ktv0YIevx
"""

import numpy as np
import tensorflow as tf
from tensorflow.keras.utils import to_categorical
from tensorflow.keras import models
from tensorflow.keras.layers import Dense, Dropout, Flatten, Conv2D, MaxPooling2D,BatchNormalization, Dropout
from tensorflow.keras.datasets import cifar10
import random
import os

#2025/0207新增
seed_value = 1234
np.random.seed(seed_value)
random.seed(seed_value)
tf.random.set_seed(seed_value)
os.environ['PYTHONHASHSEED'] = str(seed_value)

(x_Train, y_Train), (x_Test, y_Test) = cifar10.load_data()

import matplotlib.pyplot as plt
# CIFAR-10 類別名稱
class_names = ["airplane", "automobile", "bird", "cat", "deer",
               "dog", "frog", "horse", "ship", "truck"]
# 顯示前 10 張圖片
plt.figure(figsize=(10,5))
for i in range(10):
    plt.subplot(2, 5, i+1)
    plt.imshow(x_Train[i])  # CIFAR-10 是 RGB 圖片
    plt.title(class_names[y_Train[i].argmax()])  # 轉換 One-hot 為類別
    plt.axis("off")

plt.show()

#做正規化，將原本範圍在 0~255 的像素值轉換到範圍 0~1 之間
# x_Train, x_Test, = x_Train / 255.0, x_Test / 255.0
y_Train = to_categorical(y_Train, 10)  # One-hot 編碼
y_Test = to_categorical(y_Test, 10)    # One-hot 編碼
#標準化standardization
mean = np.mean(x_Train, axis=(0,1,2))  # 對 height, width, channel 軸取均值
std = np.std(x_Train, axis=(0,1,2))    # 對 height, width, channel 軸取標準差
# print(f"Mean: {mean}, Std: {std}")
x_Train = (x_Train - mean) / std
x_Test = (x_Test - mean) / std

# 定義預處理函數
def preprocess(image, label):
    image = tf.image.resize(image, (224, 224))  # 只在訓練時調整大小
    return image, label
# 使用 `tf.data.Dataset` 來動態處理
train_ds = tf.data.Dataset.from_tensor_slices((x_Train, y_Train))
train_ds = train_ds.map(preprocess).batch(32).prefetch(tf.data.AUTOTUNE)
test_ds = tf.data.Dataset.from_tensor_slices((x_Test, y_Test))
test_ds = test_ds.map(preprocess).batch(32).prefetch(tf.data.AUTOTUNE)

model = models.Sequential()

#第一組
model.add(Conv2D(filters=64, kernel_size=(3, 3), padding="same", activation="relu", input_shape=(224, 224, 3)))
model.add(Conv2D(filters=64, kernel_size=(3, 3), padding="same", activation="relu"))
model.add(MaxPooling2D(pool_size=(2, 2), strides=(2, 2)))
#第二組
model.add(Conv2D(filters=128, kernel_size=(3, 3), padding="same", activation="relu"))
model.add(Conv2D(filters=128, kernel_size=(3, 3), padding="same", activation="relu"))
model.add(MaxPooling2D(pool_size=(2, 2), strides=(2, 2)))
#第三組
model.add(Conv2D(filters=256, kernel_size=(3, 3), padding="same", activation="relu"))
model.add(Conv2D(filters=256, kernel_size=(3, 3), padding="same", activation="relu"))
model.add(Conv2D(filters=256, kernel_size=(3, 3), padding="same", activation="relu"))
model.add(MaxPooling2D(pool_size=(2, 2), strides=(2, 2)))
#第四組
model.add(Conv2D(filters=512, kernel_size=(3, 3), padding="same", activation="relu"))
model.add(Conv2D(filters=512, kernel_size=(3, 3), padding="same", activation="relu"))
model.add(Conv2D(filters=512, kernel_size=(3, 3), padding="same", activation="relu"))
model.add(MaxPooling2D(pool_size=(2, 2), strides=(2, 2)))
#第五組
model.add(Conv2D(filters=512, kernel_size=(3, 3), padding="same", activation="relu"))
model.add(Conv2D(filters=512, kernel_size=(3, 3), padding="same", activation="relu"))
model.add(Conv2D(filters=512, kernel_size=(3, 3), padding="same", activation="relu"))
model.add(MaxPooling2D(pool_size=(2, 2), strides=(2, 2)))

model.add(Flatten())
model.add(Dense(4096, activation="relu"))
model.add(Dense(4096, activation="relu"))
model.add(Dense(10,activation="softmax"))
print(model.summary())

from tensorflow.keras.optimizers import Adam
model.compile(loss='categorical_crossentropy', optimizer=Adam(learning_rate=0.00001), metrics=['accuracy'])

history = model.fit(train_ds, epochs=5)

model.evaluate(train_ds, verbose=2)

model.evaluate(test_ds, verbose=2)

import matplotlib.pyplot as plt

plt.plot(history.history["accuracy"])
plt.plot(history.history["loss"])

plt.title("Model Accuracy")
plt.ylabel("Accuracy")
plt.xlabel("Epoch")
plt.legend(["Accuracy", "Loss",])
plt.show(block=True)
